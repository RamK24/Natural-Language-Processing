{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590d4fac-534b-4dde-86dc-36317565c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e635d219-303f-48ef-a91e-5ff90da72abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self, file_path):\n",
    "        self.sonnets = []\n",
    "        self.vocab = self.create_vocab(file_path)\n",
    "        self.stoi, self.itos = self.create_dict()\n",
    "        self.file_path = file_path\n",
    "        self.max_len = max([len(i) for i in self.sonnets])\n",
    "        self.indexes = torch.arange(len(self.vocab))\n",
    "\n",
    "    def create_vocab(self, path):\n",
    "        f = open(path)\n",
    "        vocab_set = {'<SOS>', '<EOS>'}\n",
    "        sonnet = []\n",
    "        for line in f.readlines():\n",
    "            try:\n",
    "                int(line.strip())\n",
    "                if sonnet:\n",
    "                    sonnet = ['<SOS>'] + sonnet + ['<EOS>']\n",
    "                    self.sonnets.append(sonnet)\n",
    "                sonnet = []\n",
    "            except ValueError:\n",
    "                words = [i.lower().strip() for i in line.split()]\n",
    "                sonnet += (words)\n",
    "                vocab_set.update(set(words))\n",
    "        sonnet = ['<SOS>'] + sonnet + ['<EOS>']\n",
    "        self.sonnets.append(sonnet)\n",
    "        return vocab_set\n",
    "\n",
    "    def create_dict(self):\n",
    "        stoi = OrderedDict()\n",
    "        itos = OrderedDict()\n",
    "        for i, token in enumerate(self.vocab):\n",
    "            stoi[token] = i\n",
    "            itos[i] = token\n",
    "        return stoi, itos\n",
    "\n",
    "    def sonnet_to_tensor(self, sonnet):\n",
    "        x = torch.zeros(self.max_len, len(self.vocab))\n",
    "        for idx, word in enumerate(sonnet):\n",
    "            x[idx, self.stoi[word]] = 1\n",
    "        return x\n",
    "\n",
    "    def get_tensor_data(self):\n",
    "        data_tensor = torch.zeros(len(self.sonnets), self.max_len, len(self.vocab))\n",
    "        for idx, sonnet in enumerate(self.sonnets):\n",
    "            data_tensor[idx] = self.sonnet_to_tensor(sonnet)\n",
    "        return data_tensor\n",
    "\n",
    "    def word_to_one_hot(self, index, batch_size=1):\n",
    "        x = torch.zeros(batch_size, 1, len(self.vocab))\n",
    "        x[:, :, index] = 1\n",
    "        return x\n",
    "\n",
    "    def word_to_one_hot_batch(self, index):\n",
    "        x = torch.zeros(index.shape[0], 1, len(self.vocab))\n",
    "        for i, idx in enumerate(index):\n",
    "            x[i] = self.word_to_one_hot(idx)  \n",
    "        return x\n",
    "        \n",
    "    def decode(self, sonnet):\n",
    "        words = ''\n",
    "        try:\n",
    "            for idx, row in enumerate(sonnet):\n",
    "                words += self.itos[self.indexes[row.to(torch.bool)].item()] + ' '        \n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40842a2-31b3-413c-9a36-133e10f4ff73",
   "metadata": {},
   "source": [
    "<strong> Recurrent Neural Networks</strong>\n",
    "<p>  Hidden state update : </p> $$h_t = tanh(x_tW^T_{ih} + b_{ih} + h_{t-1}W^T_{hh} + b_{hh})$$\n",
    "<p>$x_t$ : input at time step t</p>\n",
    "<p>$W_{ih}$: input to hidden weight matrix</p>\n",
    "<p>$b_{ih}$: input to hidden biases</p>\n",
    "<p>$h_{t-1}$: previous hidden state</p>\n",
    "<p>$W_{hh}$: weight matrix for previous hidden state to current hidden state</p>\n",
    "<p>$h_t$: current hidden state</p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd4308-f1c4-43b9-bc85-4316a6417570",
   "metadata": {},
   "source": [
    "<strong> Gated Recurrent Unit</strong>\n",
    "\\begin{align*}\n",
    "r_t &= \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n",
    "z_t &= \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n",
    "n_t &= \\tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{(t-1)} + b_{hn})) \\\\\n",
    "h_t &= (1 - z_t) \\odot n_t + z_t \\odot h_{(t-1)}\n",
    "\\end{align*}\n",
    "\n",
    "<p>$x_t$ : input at time step t</p>\n",
    "<p>$h_{t-1}$: previous hidden state</p>\n",
    "<p>$h_t$: current hidden state</p>\n",
    "<p>$r_t$: reset gate</p>\n",
    "<p>$z_t$: update gate</p>\n",
    "<p>$n_t$: candidate for current hidden state</p>\n",
    "<p>$h_t$: current hidden state</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918f897-22f5-4661-a47c-21831ce5bdd3",
   "metadata": {},
   "source": [
    "<strong> Long short term memory</strong>\n",
    "<p>Hidden state update :</p>\n",
    "\n",
    "\\begin{align*}\n",
    "\\Gamma_u &= \\sigma(W_{iu} x_t + b_{iu} + W_{hu} h_{t-1} + b_{hu}) \\\\\n",
    "\\Gamma_f &= \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n",
    "\\tilde{c_t} &= \\tanh(W_{ic} x_t + b_{ic} + W_{hc} h_{t-1} + b_{hc}) \\\\\n",
    "\\Gamma_o &= \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n",
    "c_t &= \\Gamma_f \\odot c_{t-1} + \\Gamma_u \\odot \\tilde{c_t} \\\\\n",
    "h_t &= \\Gamma_o \\odot \\tanh(c_t)\n",
    "\\end{align*}\n",
    "\n",
    "<p>$x_t$ : input at time step t</p>\n",
    "<p>$h_{t-1}$: previous hidden state</p>\n",
    "<p>$h_t$: current hidden state</p>\n",
    "<p>$\\Gamma_u$: update gate</p>\n",
    "<p>$\\Gamma_o$: output gate</p>\n",
    "<p>$\\Gamma_f$: forget gate</p>\n",
    "<p>$\\tilde{c_t} $: candidate for current memory state</p>\n",
    "<p>$c_t$: current memory cell state</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7067dd1-1ea4-421d-b304-f6da1aa51efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer('shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2779a9ff-4c72-4863-bb90-40145bc4b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = tokenizer.get_tensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce2068e-1c86-421a-8f2e-2d81e7827c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SonnetDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "        self.samples = x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1ded3a-7630-4dee-9bc5-07b795db7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SonnetDataset(data_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f9a796-7ad6-44cf-b485-7661a01d1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqGeneration(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_cells, vocab_length, cell_init='rnn', bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_cells = num_cells\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.cell_init = cell_init\n",
    "        if cell_init == 'rnn':\n",
    "            self.cell = nn.RNN(input_size, hidden_size, num_cells, batch_first=True, bidirectional=bidirectional, dropout=0.2)\n",
    "        elif cell_init == 'gru':\n",
    "            self.cell = nn.GRU(input_size, hidden_size, num_cells, batch_first=True, bidirectional=bidirectional, dropout=0.2)\n",
    "        elif cell_init == 'lstm':\n",
    "            self.cell = nn.LSTM(input_size, hidden_size, num_cells, batch_first=True, bidirectional=bidirectional, dropout=0.2)\n",
    "        else:\n",
    "            raise Exception('Invalid cell type')\n",
    "        self.fc1 = nn.Linear(self.num_directions*hidden_size, vocab_length)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, h0=None, c0=None, device='mps'):\n",
    "        # data you pass will be the first time step only.\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_directions*self.num_cells, x.shape[0], self.hidden_size, device=device)\n",
    "        if self.cell_init == 'lstm':\n",
    "            if c0 is None:\n",
    "                c0 = torch.zeros(self.num_directions*self.num_cells, x.shape[0], self.hidden_size, device=device)\n",
    "            hidden_states, (ht_all, c0) = self.cell(x, (h0, c0))\n",
    "        else:\n",
    "            hidden_states, ht_all = self.cell(x, h0)\n",
    "            # ht will always be of the shape h0 \n",
    "        ht = hidden_states[:, -1, :]\n",
    "        logits = self.fc1(ht)\n",
    "        scores = self.softmax(logits)\n",
    "        return scores, ht_all, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d56979c-05ad-41b6-a970-46f20085873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqGeneration(len(tokenizer.vocab), 128, 2, len(tokenizer.vocab), 'lstm', True)\n",
    "# model.load_state_dict(torch.load('SeqGeneration.pth'))\n",
    "device = 'mps'\n",
    "model = model.to(device)\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567f5e53-2ce1-450f-8371-c1065c8650e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, train_params, tokenizer):\n",
    "    min_loss = float('inf')\n",
    "    epochs = train_params['epochs']\n",
    "    loss = train_params['loss']\n",
    "    optimizer = train_params['optimizer']\n",
    "    for epoch in range(epochs):\n",
    "        loss_at_batch = None\n",
    "        for x in tqdm(train_loader, desc=f'Epoch: {epoch}/{epochs}, best loss: {min_loss}'):\n",
    "            loss_at_batch = []\n",
    "            ht = None\n",
    "            c0 = None\n",
    "            x = x.to(device)\n",
    "            for t in range(x.shape[1] - 1):\n",
    "                xt = x[:, t:t+1, :]\n",
    "                scores, ht, c0 = model(xt, ht, c0)\n",
    "                next_word_index = torch.argmax(scores, dim=1)\n",
    "                labels = x[:, t+1:t+2, :]\n",
    "                labels = torch.argmax(labels, dim=2).flatten()\n",
    "                if labels.sum() == 0:\n",
    "                    break\n",
    "                loss_at_timestep = loss(scores, labels)\n",
    "                loss_at_batch.append(loss_at_timestep)\n",
    "                xt = tokenizer.word_to_one_hot_batch(next_word_index)\n",
    "                xt = xt.to(device)\n",
    "            loss_at_batch = sum(loss_at_batch)/len(loss_at_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss_at_batch.backward()\n",
    "            torch.nn.utils.clip_grad_value_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        if loss_at_batch < min_loss:\n",
    "            torch.save(model.state_dict(), 'SeqGeneration_lstm.pth')\n",
    "            min_loss = loss_at_batch\n",
    "            print('saving model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65aca48-6774-4ddd-a3a4-9fe0dd272db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, sos_tensor, tokenizer):\n",
    "    curr_token = ''\n",
    "    sonnet = ''\n",
    "    pred = ''\n",
    "    ht = None\n",
    "    model.eval()\n",
    "    with torch.no_grad():  \n",
    "        while curr_token != '<EOS>' and len(sonnet.split()) < tokenizer.max_len:\n",
    "            sonnet += pred + ' '\n",
    "            scores, ht, ct = model(sos_tensor, ht, None, 'cpu')\n",
    "            # pred = tokenizer.itos[torch.argmax(scores).item()] always generates the same sequence\n",
    "            # sample to generate different sequences each time.\n",
    "            pred = tokenizer.itos[torch.argmax(scores).item()]\n",
    "            random_word_index = torch.multinomial(torch.exp(scores).flatten(), num_samples=1).item()\n",
    "            curr_token = pred\n",
    "            sos_tensor = tokenizer.word_to_one_hot(tokenizer.stoi[tokenizer.itos[random_word_index]], 1)\n",
    "        return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9005b3-692f-4630-966e-6a2cabd579ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200, best loss: inf: 100%|█████████████| 10/10 [00:07<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, best loss: 7.480195045471191: 100%|█| 10/10 [00:06<00:00,  1.52it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/200, best loss: 6.760316848754883: 100%|█| 10/10 [00:06<00:00,  1.54it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/200, best loss: 6.553677558898926: 100%|█| 10/10 [00:06<00:00,  1.54it/\n",
      "Epoch: 4/200, best loss: 6.553677558898926: 100%|█| 10/10 [00:06<00:00,  1.52it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/200, best loss: 6.544550895690918: 100%|█| 10/10 [00:06<00:00,  1.53it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.50it/\n",
      "Epoch: 7/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.52it/\n",
      "Epoch: 8/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.46it/\n",
      "Epoch: 9/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.50it/\n",
      "Epoch: 10/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.49it\n",
      "Epoch: 11/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.50it\n",
      "Epoch: 12/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 13/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 14/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 15/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 16/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 17/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 18/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 19/200, best loss: 6.442972183227539: 100%|█| 10/10 [00:06<00:00,  1.53it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/200, best loss: 6.39254093170166: 100%|█| 10/10 [00:06<00:00,  1.54it/\n",
      "Epoch: 21/200, best loss: 6.39254093170166: 100%|█| 10/10 [00:06<00:00,  1.54it/\n",
      "Epoch: 22/200, best loss: 6.39254093170166: 100%|█| 10/10 [00:06<00:00,  1.53it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 24/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 25/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 26/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 27/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.55it\n",
      "Epoch: 28/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.55it\n",
      "Epoch: 29/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.55it\n",
      "Epoch: 30/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 31/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 32/200, best loss: 6.244823932647705: 100%|█| 10/10 [00:06<00:00,  1.45it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 33/200, best loss: 6.216181755065918: 100%|█| 10/10 [00:06<00:00,  1.50it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 34/200, best loss: 6.1520538330078125: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 35/200, best loss: 6.10606575012207: 100%|█| 10/10 [00:06<00:00,  1.51it/\n",
      "Epoch: 36/200, best loss: 6.10606575012207: 100%|█| 10/10 [00:06<00:00,  1.51it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 37/200, best loss: 5.804404258728027: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 38/200, best loss: 5.804404258728027: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 39/200, best loss: 5.804404258728027: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 40/200, best loss: 5.804404258728027: 100%|█| 10/10 [00:06<00:00,  1.52it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 41/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 42/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 43/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 44/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 45/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 46/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 47/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 48/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 49/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 50/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 51/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 52/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 53/200, best loss: 5.752346992492676: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 54/200, best loss: 5.5898356437683105: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 55/200, best loss: 5.5898356437683105: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 56/200, best loss: 5.5898356437683105: 100%|█| 10/10 [00:06<00:00,  1.54i\n",
      "Epoch: 57/200, best loss: 5.5898356437683105: 100%|█| 10/10 [00:06<00:00,  1.55i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 58/200, best loss: 5.418381214141846: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 59/200, best loss: 5.418381214141846: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 60/200, best loss: 5.418381214141846: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 61/200, best loss: 5.418381214141846: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 62/200, best loss: 5.418381214141846: 100%|█| 10/10 [00:06<00:00,  1.53it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 63/200, best loss: 5.39573335647583: 100%|█| 10/10 [00:06<00:00,  1.53it/\n",
      "Epoch: 64/200, best loss: 5.39573335647583: 100%|█| 10/10 [00:06<00:00,  1.53it/\n",
      "Epoch: 65/200, best loss: 5.39573335647583: 100%|█| 10/10 [00:06<00:00,  1.52it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 66/200, best loss: 5.25770378112793: 100%|█| 10/10 [00:06<00:00,  1.52it/\n",
      "Epoch: 67/200, best loss: 5.25770378112793: 100%|█| 10/10 [00:06<00:00,  1.51it/\n",
      "Epoch: 68/200, best loss: 5.25770378112793: 100%|█| 10/10 [00:06<00:00,  1.52it/\n",
      "Epoch: 69/200, best loss: 5.25770378112793: 100%|█| 10/10 [00:06<00:00,  1.50it/\n",
      "Epoch: 70/200, best loss: 5.25770378112793: 100%|█| 10/10 [00:06<00:00,  1.51it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 71/200, best loss: 5.220528602600098: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 72/200, best loss: 5.220528602600098: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 73/200, best loss: 5.220528602600098: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 74/200, best loss: 5.220528602600098: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 75/200, best loss: 5.124361515045166: 100%|█| 10/10 [00:06<00:00,  1.53it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 76/200, best loss: 5.10618257522583: 100%|█| 10/10 [00:06<00:00,  1.52it/\n",
      "Epoch: 77/200, best loss: 5.10618257522583: 100%|█| 10/10 [00:06<00:00,  1.54it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 78/200, best loss: 5.063533782958984: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 79/200, best loss: 5.063533782958984: 100%|█| 10/10 [00:06<00:00,  1.53it\n",
      "Epoch: 80/200, best loss: 5.063533782958984: 100%|█| 10/10 [00:06<00:00,  1.52it\n",
      "Epoch: 81/200, best loss: 5.063533782958984: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 82/200, best loss: 5.003179550170898: 100%|█| 10/10 [00:06<00:00,  1.50it\n",
      "Epoch: 83/200, best loss: 5.003179550170898: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 84/200, best loss: 4.873672008514404: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 85/200, best loss: 4.843679904937744: 100%|█| 10/10 [00:06<00:00,  1.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 86/200, best loss: 4.788336753845215: 100%|█| 10/10 [00:06<00:00,  1.54it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 87/200, best loss: 4.756350040435791: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 88/200, best loss: 4.756350040435791: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 89/200, best loss: 4.756350040435791: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 90/200, best loss: 4.756350040435791: 100%|█| 10/10 [00:07<00:00,  1.41it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 91/200, best loss: 4.731354713439941: 100%|█| 10/10 [00:06<00:00,  1.45it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 92/200, best loss: 4.65305233001709: 100%|█| 10/10 [00:07<00:00,  1.34it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 93/200, best loss: 4.652480125427246: 100%|█| 10/10 [00:07<00:00,  1.36it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 94/200, best loss: 4.634428024291992: 100%|█| 10/10 [00:07<00:00,  1.43it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 95/200, best loss: 4.5104289054870605: 100%|█| 10/10 [00:07<00:00,  1.28i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 96/200, best loss: 4.484066009521484: 100%|█| 10/10 [00:06<00:00,  1.47it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 97/200, best loss: 4.482104301452637: 100%|█| 10/10 [00:06<00:00,  1.54it\n",
      "Epoch: 98/200, best loss: 4.482104301452637: 100%|█| 10/10 [00:06<00:00,  1.51it\n",
      "Epoch: 99/200, best loss: 4.482104301452637: 100%|█| 10/10 [00:06<00:00,  1.53it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100/200, best loss: 4.335834980010986: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 101/200, best loss: 4.335834980010986: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 102/200, best loss: 4.335834980010986: 100%|█| 10/10 [00:06<00:00,  1.53i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 103/200, best loss: 4.286771297454834: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 104/200, best loss: 4.240783214569092: 100%|█| 10/10 [00:07<00:00,  1.40i\n",
      "Epoch: 105/200, best loss: 4.240783214569092: 100%|█| 10/10 [00:06<00:00,  1.43i\n",
      "Epoch: 106/200, best loss: 4.240783214569092: 100%|█| 10/10 [00:07<00:00,  1.41i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 107/200, best loss: 4.153110027313232: 100%|█| 10/10 [00:06<00:00,  1.49i\n",
      "Epoch: 108/200, best loss: 4.153110027313232: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 109/200, best loss: 4.047351837158203: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 110/200, best loss: 4.047351837158203: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 111/200, best loss: 4.047351837158203: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 112/200, best loss: 4.004422187805176: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 113/200, best loss: 4.004422187805176: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 114/200, best loss: 3.9444375038146973: 100%|█| 10/10 [00:06<00:00,  1.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 115/200, best loss: 3.708221197128296: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 116/200, best loss: 3.708221197128296: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 117/200, best loss: 3.708221197128296: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 118/200, best loss: 3.708221197128296: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 119/200, best loss: 3.708221197128296: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 120/200, best loss: 3.652432918548584: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 121/200, best loss: 3.652432918548584: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 122/200, best loss: 3.652432918548584: 100%|█| 10/10 [00:06<00:00,  1.54i\n",
      "Epoch: 123/200, best loss: 3.652432918548584: 100%|█| 10/10 [00:06<00:00,  1.48i\n",
      "Epoch: 124/200, best loss: 3.652432918548584: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 125/200, best loss: 3.520200729370117: 100%|█| 10/10 [00:06<00:00,  1.50i\n",
      "Epoch: 126/200, best loss: 3.520200729370117: 100%|█| 10/10 [00:06<00:00,  1.50i\n",
      "Epoch: 127/200, best loss: 3.520200729370117: 100%|█| 10/10 [00:06<00:00,  1.50i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 128/200, best loss: 3.488630771636963: 100%|█| 10/10 [00:06<00:00,  1.47i\n",
      "Epoch: 129/200, best loss: 3.488630771636963: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 130/200, best loss: 3.488630771636963: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 131/200, best loss: 3.329408645629883: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 132/200, best loss: 3.329408645629883: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 133/200, best loss: 3.302119493484497: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 134/200, best loss: 3.302119493484497: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 135/200, best loss: 3.302119493484497: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 136/200, best loss: 3.2707035541534424: 100%|█| 10/10 [00:06<00:00,  1.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 137/200, best loss: 3.205918073654175: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 138/200, best loss: 3.205918073654175: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 139/200, best loss: 3.0541133880615234: 100%|█| 10/10 [00:06<00:00,  1.50\n",
      "Epoch: 140/200, best loss: 3.0541133880615234: 100%|█| 10/10 [00:06<00:00,  1.51\n",
      "Epoch: 141/200, best loss: 3.0541133880615234: 100%|█| 10/10 [00:06<00:00,  1.52\n",
      "Epoch: 142/200, best loss: 3.0541133880615234: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 143/200, best loss: 3.0541133880615234: 100%|█| 10/10 [00:06<00:00,  1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 144/200, best loss: 3.036862373352051: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 145/200, best loss: 2.984029769897461: 100%|█| 10/10 [00:06<00:00,  1.49i\n",
      "Epoch: 146/200, best loss: 2.984029769897461: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 147/200, best loss: 2.956364393234253: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 148/200, best loss: 2.956364393234253: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 149/200, best loss: 2.956364393234253: 100%|█| 10/10 [00:06<00:00,  1.53i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 150/200, best loss: 2.879908323287964: 100%|█| 10/10 [00:06<00:00,  1.54i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 151/200, best loss: 2.6977150440216064: 100%|█| 10/10 [00:06<00:00,  1.52\n",
      "Epoch: 152/200, best loss: 2.6977150440216064: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 153/200, best loss: 2.6977150440216064: 100%|█| 10/10 [00:06<00:00,  1.54\n",
      "Epoch: 154/200, best loss: 2.6977150440216064: 100%|█| 10/10 [00:06<00:00,  1.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 155/200, best loss: 2.6623713970184326: 100%|█| 10/10 [00:06<00:00,  1.52\n",
      "Epoch: 156/200, best loss: 2.6623713970184326: 100%|█| 10/10 [00:06<00:00,  1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 157/200, best loss: 2.6055119037628174: 100%|█| 10/10 [00:06<00:00,  1.48\n",
      "Epoch: 158/200, best loss: 2.6055119037628174: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 159/200, best loss: 2.6055119037628174: 100%|█| 10/10 [00:06<00:00,  1.54\n",
      "Epoch: 160/200, best loss: 2.6055119037628174: 100%|█| 10/10 [00:06<00:00,  1.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 161/200, best loss: 2.6040306091308594: 100%|█| 10/10 [00:06<00:00,  1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 162/200, best loss: 2.5842671394348145: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 163/200, best loss: 2.5842671394348145: 100%|█| 10/10 [00:06<00:00,  1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 164/200, best loss: 2.479668617248535: 100%|█| 10/10 [00:06<00:00,  1.53i\n",
      "Epoch: 165/200, best loss: 2.479668617248535: 100%|█| 10/10 [00:06<00:00,  1.54i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 166/200, best loss: 2.4312191009521484: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 167/200, best loss: 2.4312191009521484: 100%|█| 10/10 [00:06<00:00,  1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 168/200, best loss: 2.3524136543273926: 100%|█| 10/10 [00:06<00:00,  1.53\n",
      "Epoch: 169/200, best loss: 2.3524136543273926: 100%|█| 10/10 [00:06<00:00,  1.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 170/200, best loss: 2.321885824203491: 100%|█| 10/10 [00:06<00:00,  1.52i\n",
      "Epoch: 171/200, best loss: 2.321885824203491: 100%|█| 10/10 [00:06<00:00,  1.53i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 172/200, best loss: 2.273533344268799: 100%|█| 10/10 [00:06<00:00,  1.48i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 173/200, best loss: 2.259803295135498: 100%|█| 10/10 [00:06<00:00,  1.47i\n",
      "Epoch: 174/200, best loss: 2.259803295135498: 100%|█| 10/10 [00:06<00:00,  1.50i\n",
      "Epoch: 175/200, best loss: 2.259803295135498: 100%|█| 10/10 [00:06<00:00,  1.51i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 176/200, best loss: 2.2388885021209717: 100%|█| 10/10 [00:06<00:00,  1.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 177/200, best loss: 2.137296199798584: 100%|█| 10/10 [00:06<00:00,  1.47i\n",
      "Epoch: 178/200, best loss: 2.137296199798584: 100%|█| 10/10 [00:06<00:00,  1.51i\n",
      "Epoch: 179/200, best loss: 2.137296199798584: 100%|█| 10/10 [00:06<00:00,  1.52i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 180/200, best loss: 2.123990058898926: 100%|█| 10/10 [00:06<00:00,  1.49i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 181/200, best loss: 2.0945470333099365: 100%|█| 10/10 [00:06<00:00,  1.50\n",
      "Epoch: 182/200, best loss: 2.0945470333099365: 100%|█| 10/10 [00:06<00:00,  1.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 183/200, best loss: 2.0410103797912598: 100%|█| 10/10 [00:06<00:00,  1.52\n",
      "Epoch: 184/200, best loss: 2.0410103797912598: 100%|█| 10/10 [00:06<00:00,  1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 185/200, best loss: 1.922293782234192: 100%|█| 10/10 [00:06<00:00,  1.54i\n",
      "Epoch: 186/200, best loss: 1.922293782234192: 100%|█| 10/10 [00:06<00:00,  1.54i\n",
      "Epoch: 187/200, best loss: 1.922293782234192: 100%|█| 10/10 [00:06<00:00,  1.54i\n",
      "Epoch: 188/200, best loss: 1.922293782234192: 100%|█| 10/10 [00:06<00:00,  1.54i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 189/200, best loss: 1.8946218490600586: 100%|█| 10/10 [00:06<00:00,  1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 190/200, best loss: 1.8923827409744263: 100%|█| 10/10 [00:06<00:00,  1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 191/200, best loss: 1.8654778003692627: 100%|█| 10/10 [00:06<00:00,  1.51\n",
      "Epoch: 192/200, best loss: 1.8654778003692627: 100%|█| 10/10 [00:06<00:00,  1.44\n",
      "Epoch: 193/200, best loss: 1.8654778003692627: 100%|█| 10/10 [00:06<00:00,  1.51\n",
      "Epoch: 194/200, best loss: 1.8654778003692627: 100%|█| 10/10 [00:06<00:00,  1.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 195/200, best loss: 1.856586217880249: 100%|█| 10/10 [00:07<00:00,  1.40i\n",
      "Epoch: 196/200, best loss: 1.856586217880249: 100%|█| 10/10 [00:06<00:00,  1.44i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 197/200, best loss: 1.8069896697998047: 100%|█| 10/10 [00:07<00:00,  1.30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 198/200, best loss: 1.7870066165924072: 100%|█| 10/10 [00:07<00:00,  1.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 199/200, best loss: 1.769547939300537: 100%|█| 10/10 [00:06<00:00,  1.47i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_params = {'epochs': 200, 'loss': loss, 'optimizer': optimizer} # set epochs to train\n",
    "train(model, train_loader, train_params, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef94acc3-8a00-471e-bdaf-41dd08b04a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' so centre when nothing power not beauty want all power and the fever his be subject and thou fear a time lovely me my lovely what gentle thou nothing birth, to did supposing thee thou live, want me winter check thee will, be his the power once live, i will, thee live, and wish, the lovely not fear and fever of live, were me creatures of heart of time the power and live, the power live, thee thou centre thee creatures thee will, of fear lovely with will, blamed thee heart substance her beauty thee time of the old want that live, power journey to journey and force, hath show creatures thee as lovely to my lovely with heart power nothing me gentle of love, check not live, to time creatures me '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('SeqGeneration_lstm.pth'))  # with lstm\n",
    "model.to('cpu') \n",
    "generate_text(model, tokenizer.word_to_one_hot(tokenizer.stoi['<SOS>'], 1), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3158d2af-df34-4a86-8084-9d32db7cad03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasodasairamkandikonda/Desktop/Pytorch/env/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" devouring wond'ring prophecies hid wond'ring wond'ring well-contented unknown, very barrenly fire barrenly rough heaven: therefore endowed, lend least o'erpressed wont ceremony wond'ring stars moan prophecies out. deserts seeing moan crown devise. power disgrace. sweets: prophecies faster nor endowed, go, glad their noon: sullen stars budding contend. weed, fed, endowed, poor crown wooing celestial ward, wailing world, preserve preserve preserve preserve preserve of stop stop world, preserve preserve preserve preserve of light stop world, preserve preserve preserve preserve preserve preserve world, preserve preserve preserve preserve preserve world, preserve preserve preserve preserve preserve preserve preserve preserve preserve preserve preserve preserve preserve preserve world, preserve world, preserve preserve preserve world, world, preserve preserve preserve preserve preserve world, that world, preserve preserve hopes, preserve merit? world, world, preserve world, preserve preserve preserve world, world, preserve world, \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SeqGeneration(len(tokenizer.vocab), 128, 1, len(tokenizer.vocab), 'rnn', True)  #with rnns\n",
    "model.load_state_dict(torch.load('SeqGeneration.pth'))\n",
    "model.to('cpu')\n",
    "generate_text(model, tokenizer.word_to_one_hot(tokenizer.stoi['<SOS>'], 1), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83f361-afbe-475a-99c8-129978e69afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4fa56c9-17f6-48eb-8de9-047125bd748c",
   "metadata": {},
   "source": [
    "<p> LSTMs were able to generate a <EOS> token before the specifed max limit.</p>\n",
    "<p> RNNs however could not do this and relatively bad generation.</p>\n",
    "<p> In the future, we will use <strong>Attention</strong> to make these models better. Attention module helps network focus on specific parts of sentence. This context helps model generate better sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009bd37-1ff1-4c34-816c-add91d609d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925166f2-815b-4f44-9af1-b35bd12896e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec2cc37-0bbe-4db0-a8a2-5bf664ac31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "login_token = os.getenv('LOGIN_TOKEN')\n",
    "login(login_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4faa8968-5625-4444-94fb-f5a374f2a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/ykandik/.cache/huggingface/datasets/Abdulrhman37___json/Abdulrhman37--metallurgy-qa-19dc6936f18e311d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28e71be59994f4bbc0d30c1a53e1f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"Abdulrhman37/metallurgy-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab461d9c-4d82-44e2-ac65-943af77405d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 11:53:29.702557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-25 11:53:29.702582: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'google/gemma-3-1b-pt'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0373ca5-3843-4914-b67b-71e611014bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(example):\n",
    "     # return [\n",
    "     #     [{'role': \"user\", \n",
    "     #       'content': [{\"type\": \"text\", \"text\": example['instruction']},]\n",
    "     #      },\n",
    "     #     {'role': \"assistant\", \"content\": [{\"type\": \"text\", \"text\": example['output']}, ]\n",
    "     #     }\n",
    "     #     ]\n",
    "     # ]\n",
    "    return f\"question: {example['instruction']} \\n response: {example['output']}\"\n",
    "def tokenize_function(examples):\n",
    "    text = process_text(examples)\n",
    "    inputs = tokenizer(text,\n",
    "    return_tensors=\"pt\", padding='max_length', max_length=1024, truncation=True)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "925331e4-25fb-4e31-ae88-cdff0ee83aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3648 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/626 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_split = ds[\"train\"].train_test_split(test_size=0.3)\n",
    "train_ds = train_test_split['train']\n",
    "test_ds = train_test_split['test'].train_test_split(test_size=0.4)\n",
    "val_ds = test_ds['test']\n",
    "test_ds = test_ds['train']\n",
    "train_ds = train_ds.map(lambda x: {\"inputs\": tokenize_function(x)})\n",
    "val_ds = val_ds.map(lambda x: {\"inputs\": tokenize_function(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75b1901-c2d1-41fc-907c-b704ca89e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "        self.samples = ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.ds[idx]['inputs']\n",
    "        return {'input_ids': torch.tensor(tokens['input_ids']), \n",
    "               'attention_mask': torch.tensor(tokens['attention_mask'])}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d1e219-3031-46cd-bd93-f662e6a60e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_ds)\n",
    "val_dataset = TextDataset(val_ds)\n",
    "test_dataset = TextDataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d457b2-9136-464b-a032-16f103675302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2)\n",
    "test_dataset = DataLoader(test_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c336e97-46d3-46d3-8474-2f38ef318c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_loss(val_loader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = []\n",
    "        for dic in val_loader:\n",
    "            input_ids = dic['input_ids'].squeeze(1).to(model.device)\n",
    "            attention_mask = dic['attention_mask'].squeeze(1).to(model.device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            val_loss.append(outputs.loss)\n",
    "        return sum(val_loss)/len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8b3356-3238-43b8-a828-163f271de28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper():\n",
    "    def __init__(self, patience=15, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.min_validation_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "\n",
    "    def early_stop(self, model, validation_loss, path):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            print('Saving model') \n",
    "            torch.save(model.state_dict(), f'{path}.pth')\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "638e8ccc-6e85-4495-a30c-e8e978a8effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, train_params, path='model'):\n",
    "    stopper = EarlyStopper()\n",
    "    epochs = train_params['epochs']\n",
    "    optimizer = train_params['optimizer']\n",
    "    val_loss = None\n",
    "    train_loss = None\n",
    "    for epoch in range(epochs):\n",
    "        loss_at_epoch = []\n",
    "        for dic in tqdm(train_loader, desc=f'Epoch:{epoch}/{epochs} train_loss: {train_loss} val_loss: {val_loss}'):\n",
    "            input_ids = dic['input_ids'].squeeze(1).to(model.device)\n",
    "            attention_mask = dic['attention_mask'].squeeze(1).to(model.device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss_val = outputs.loss\n",
    "            loss_at_epoch.append(loss_val)\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = sum(loss_at_epoch)/len(loss_at_epoch)\n",
    "        val_loss = get_validation_loss(val_loader, model)\n",
    "        stop = stopper.early_stop(model, val_loss, path)\n",
    "        if stop:\n",
    "            print(f'Stopping early at epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac7cf0b1-12fa-4595-a54e-178e6b21125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'epochs': 0, 'optimizer': optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "825872dc-ab62-4049-bc0c-3dec60e3cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, weights in model.named_parameters():\n",
    "    if 'layers' in name:\n",
    "        name_toks = name.split('.')\n",
    "        num = int(name_toks[2])\n",
    "        if num < 10:\n",
    "            weights.requires_grad = False  # keeping the first 10 layers frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b00324c-eb80-465a-832a-ba1c2917babe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0/5 train_loss: None val_loss: None: 100%|██████████████████████████████| 1824/1824 [06:34<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1/5 train_loss: 0.7636858224868774 val_loss: 0.5677177906036377: 100%|██| 1824/1824 [06:35<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:2/5 train_loss: 0.5057775974273682 val_loss: 0.528381884098053: 100%|███| 1824/1824 [06:37<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:3/5 train_loss: 0.4105050563812256 val_loss: 0.5251997709274292: 100%|██| 1824/1824 [06:39<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:4/5 train_loss: 0.3305712342262268 val_loss: 0.5130376219749451: 100%|██| 1824/1824 [06:37<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, model, train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bfd37cd-1c9a-49df-a1bd-cc06e59c1c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62dd609-a429-4ef7-9563-c3936bd48878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(example):\n",
    "    return f\"question: {example['instruction']} \\n response: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c5c6319-da38-441b-be39-b43da13bfb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = test_ds.map(lambda x: {\"inputs\": tokenize_function(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3b54c-a3e0-4d72-825c-b30e3cab232b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ykandik/spack/opt/spack/linux-rocky9-zen3/gcc-11.4.1/anaconda3-2022.10-gses3lscf5npdkzsxv5aftwfizsukolo/envs/explain/lib/python3.10/site-packages/transformers/generation/utils.py:2208: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out_tokens = model.generate(inputs=torch.tensor(test_ds['inputs'][2]['input_ids'].to(model.device)), attention_mask=torch.tensor(test_ds['inputs'][2]['attention_mask'].to(model.device)), max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d0a1f-ce09-4122-bb70-245a360be997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(out_tokens[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38579a1f-36e9-43cb-862c-96a9a669c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df11268-3ba8-4155-a0f6-507130998a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
